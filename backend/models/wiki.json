{
  "entries": [
    {
      "id": "wiki_arch_001",
      "question": "What is the overall architecture of this interview platform?",
      "answer": "This is an AI-powered interview platform with a monolithic FastAPI backend and Next.js frontend. The backend handles WebSocket communication for real-time interviews, LLM integration via Google Gemini for question generation and evaluation, and JSON-based data storage. Key components include InterviewController (core/interview_controller.py) for interview flow management, ConnectionManager (main.py) for WebSocket handling, and Evaluator (evaluation/evaluator.py) for response scoring. The frontend uses React with Tailwind CSS for a modern, responsive UI.",
      "category": "Architecture",
      "code_refs": [
        "backend/main.py",
        "backend/core/interview_controller.py",
        "frontend/src/app/page.tsx"
      ],
      "keywords": [
        "architecture",
        "fastapi",
        "next.js",
        "monolithic",
        "websocket",
        "gemini",
        "interview",
        "platform",
        "overview",
        "structure",
        "tech stack"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_interview_001",
      "question": "How does the interview lifecycle work from start to finish?",
      "answer": "The interview lifecycle has 5 phases: 1) **Session Creation**: Admin creates a session via /api/interviews/quick-start (Quick Start mode) or through position management. 2) **Connection**: Candidate and Admin connect via WebSocket to /ws endpoint. 3) **Question Flow**: Questions are loaded from question bank, presented one at a time. After each answer, follow-up questions are generated by AI. 4) **Evaluation**: Each response is evaluated using the Evaluator class with scoring rubrics. 5) **Completion**: Admin ends the interview, results are saved to candidate_results folder, and feedback can be generated using the Feedback Agent.",
      "category": "Interview Flow",
      "code_refs": [
        "backend/core/interview_controller.py",
        "backend/main.py"
      ],
      "keywords": [
        "interview",
        "lifecycle",
        "flow",
        "session",
        "websocket",
        "question",
        "evaluation",
        "completion",
        "start",
        "end",
        "phases"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_quickstart_001",
      "question": "What is Quick Start mode and how does it differ from regular mode?",
      "answer": "Quick Start mode allows admins to begin an interview immediately without pre-configuring a position or uploading resumes. In Quick Start: 1) Candidate info is collected on-the-fly via a form. 2) Questions come from the generic question bank (questions/python.json or questions/java.json). 3) No position-specific JD matching. Regular mode requires: selecting an account, position, and candidate beforehand, with JD-matched questions and scoring. Quick Start is ideal for ad-hoc interviews; Regular mode for structured hiring pipelines.",
      "category": "Interview Modes",
      "code_refs": [
        "backend/main.py",
        "frontend/src/app/active/page.tsx"
      ],
      "keywords": [
        "quick start",
        "adhoc",
        "immediate",
        "interview mode",
        "regular",
        "position",
        "difference",
        "comparison"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_websocket_001",
      "question": "How does WebSocket communication work between candidate and admin?",
      "answer": "The WebSocket system uses a ConnectionManager class in main.py to handle real-time bidirectional communication. Key aspects: 1) Both views connect to /ws?view=candidate or /ws?view=admin. 2) Messages are JSON-formatted with type field (e.g., 'answer', 'next_question', 'interview_end'). 3) Admin can see candidate's code in real-time via code_update messages. 4) Expert mode allows admin to approve/edit AI-generated follow-ups before they're sent. 5) Reconnection logic restores session state using session_id stored in interview_sessions.json.",
      "category": "Real-time Communication",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "websocket",
        "real-time",
        "connection",
        "candidate",
        "admin",
        "message",
        "sync",
        "live",
        "communication"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_evaluation_001",
      "question": "How are candidate responses evaluated and scored?",
      "answer": "Response evaluation uses the Evaluator class (evaluation/evaluator.py) with a multi-factor scoring rubric: 1) **Factual Correctness** (for true/false, yes/no questions): Binary 0/100 score. 2) **Keyword Coverage**: Checks expected_keywords from question definition. 3) **Completeness**: Measures how thoroughly the response addresses the question. 4) **Technical Accuracy**: LLM validates technical claims. 5) **Depth & Clarity**: Quality of explanation. Weights are defined per question in the question bank. Final score is a weighted average.",
      "category": "Evaluation & Scoring",
      "code_refs": [
        "backend/evaluation/evaluator.py",
        "backend/models/question_bank.json"
      ],
      "keywords": [
        "evaluation",
        "scoring",
        "rubric",
        "accuracy",
        "completeness",
        "keywords",
        "score",
        "response",
        "grading"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_gemini_001",
      "question": "How is Google Gemini integrated for AI features?",
      "answer": "Gemini integration is handled by the GeminiClient class (llm/gemini_client.py). It's used for: 1) **Follow-up Question Generation**: Creates contextual follow-ups based on candidate's response quality and gaps. 2) **Response Evaluation**: Validates technical accuracy of answers. 3) **Feedback Generation**: Creates detailed interview reports via the Feedback Agent. The client uses gemma-3-27b-it model with configurable temperature/tokens per operation. API key is set via GEMINI_API_KEY environment variable.",
      "category": "LLM Integration",
      "code_refs": [
        "backend/llm/gemini_client.py",
        "backend/agents/feedback_agent.py"
      ],
      "keywords": [
        "gemini",
        "llm",
        "ai",
        "google",
        "follow-up",
        "generation",
        "evaluation",
        "feedback",
        "agent",
        "api"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_followup_001",
      "question": "How are follow-up questions generated?",
      "answer": "Follow-up generation uses the Strategy Factory pattern (strategies/strategy_factory.py) with multiple strategies: 1) **Depth Focused**: Digs deeper when candidate shows weakness in an area. 2) **Breadth Focused**: Explores more topics when current topic is well-covered. 3) **Clarification**: Asks for specifics when answer is vague. Selection is based on response quality and coverage. In Expert Mode, admin reviews follow-ups before they're sent. Follow-up count is configurable via MAX_FOLLOWUPS_PER_QUESTION in config.",
      "category": "Question Generation",
      "code_refs": [
        "backend/strategies/strategy_factory.py",
        "backend/strategies/depth_focused.py"
      ],
      "keywords": [
        "follow-up",
        "question",
        "generation",
        "strategy",
        "depth",
        "breadth",
        "ai",
        "dynamic",
        "adaptive"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_questionbank_001",
      "question": "How is the question bank structured?",
      "answer": "The question bank (models/question_bank.json) contains 50+ questions organized by: 1) **type**: coding, open_ended, true_false, multiple_choice. 2) **category**: coding, conceptual, system_design, problem_solving. 3) **difficulty**: easy, medium, hard. 4) **language**: python, java, general. 5) **experience_levels**: junior, mid, senior, lead. Each question has: text, starter_code (for coding), test_cases, expected_keywords, hints, and evaluation_rubric with weights. Quick Start uses language-specific files (questions/python.json, questions/java.json).",
      "category": "Data Models",
      "code_refs": [
        "backend/models/question_bank.json",
        "backend/questions/python.json",
        "backend/questions/java.json"
      ],
      "keywords": [
        "question bank",
        "questions",
        "coding",
        "conceptual",
        "difficulty",
        "category",
        "rubric",
        "structure"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_candidate_001",
      "question": "How does candidate matching work for positions?",
      "answer": "Candidate matching uses calculate_candidate_match_score in main.py. The algorithm: 1) **Skill Overlap**: Compares position required_skills with candidate skills (partial matching for related skills, e.g., Django boosts Python). 2) **Language Filter**: Prioritizes Python/Java proficiency as specified by position. 3) **Experience Alignment**: Matches years of experience to position requirements. 4) **Generates 0-100% score**: Used to rank candidates on the position detail page. Resumes are stored in resumes/resumes.json with parsed skills.",
      "category": "Candidate Matching",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "candidate",
        "matching",
        "score",
        "skills",
        "experience",
        "position",
        "ranking",
        "algorithm",
        "resume"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_expertmode_001",
      "question": "What is Expert Mode and how does it work?",
      "answer": "Expert Mode gives admin control over AI-generated follow-ups before they're sent to candidates. When enabled: 1) AI generates a follow-up and shows it to admin. 2) Admin can Approve (send as-is), Edit (modify text), or Override (write custom question). 3) Expert feedback is logged for evolutionary learning. 4) Improves AI quality over time by incorporating human judgment. Toggle via expert_mode flag when creating session. Uses pending_followup pattern in InterviewController.",
      "category": "Expert Mode",
      "code_refs": [
        "backend/core/interview_controller.py",
        "backend/main.py"
      ],
      "keywords": [
        "expert mode",
        "admin control",
        "approve",
        "edit",
        "override",
        "follow-up",
        "human-in-loop",
        "approval"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_feedback_001",
      "question": "How does feedback generation work?",
      "answer": "Feedback generation uses the Feedback Agent (agents/feedback_agent.py): 1) Admin clicks 'Generate Report' in Results page. 2) Chooses type: 'detailed' (formal EPAM-style) or 'short' (bullet points). 3) Agent reads interview transcript and scores from session log. 4) LLM generates structured feedback with strengths, weaknesses, recommendation. 5) Admin reviews/edits, then clicks 'Approve & Publish'. 6) Published feedback is stored in result file and can be shared via public link with QR code.",
      "category": "Feedback & Results",
      "code_refs": [
        "backend/agents/feedback_agent.py",
        "frontend/src/components/ResultsHistory.tsx"
      ],
      "keywords": [
        "feedback",
        "report",
        "generation",
        "publish",
        "approve",
        "review",
        "summary",
        "agent",
        "detailed",
        "short"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_storage_001",
      "question": "How is data stored in the application?",
      "answer": "All data is stored in JSON files in the backend/models directory: 1) **organizations.json**: Company/org hierarchy. 2) **accounts.json**: Client accounts under organizations. 3) **positions.json**: Job positions with JD, skills, interview config. 4) **interview_sessions.json**: All session metadata (status, candidate info, timestamps). 5) **candidate_results/**: Per-candidate result files with interview transcripts and scores. 6) **question_bank.json**: Full question library. 7) **wiki.json**: This knowledge base. No database required - pure file-based storage.",
      "category": "Data Storage",
      "code_refs": [
        "backend/models/"
      ],
      "keywords": [
        "storage",
        "json",
        "files",
        "database",
        "persistence",
        "sessions",
        "results",
        "models",
        "data"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_results_001",
      "question": "How are interview results stored and accessed?",
      "answer": "Results are stored in backend/candidate_results/{candidate_name}+{date}_result.json. Structure includes: 1) **interviews[]**: Array of interview records with session_id, scores, transcript. 2) **feedback_report**: Generated feedback with status (PENDING/APPROVED/REJECTED). 3) **share_token**: Public share link token. Accessed via: /api/admin/results (list all), /api/results/{session_id}/status (single), /share/{token} (public view). Results page uses pagination (10/page) and shows Pending Review / Published status.",
      "category": "Feedback & Results",
      "code_refs": [
        "backend/candidate_results/",
        "frontend/src/app/admin/results/page.tsx"
      ],
      "keywords": [
        "results",
        "transcript",
        "feedback",
        "share",
        "publish",
        "storage",
        "candidate",
        "report",
        "status"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_api_001",
      "question": "What are the main API endpoints?",
      "answer": "Key API endpoints in main.py: **Interview**: POST /api/interviews/quick-start, /api/sessions/active, /api/sessions/cleanup. **Results**: GET /api/admin/results, POST /api/feedback/generate, /api/feedback/approve, /api/feedback/reject. **Management**: CRUD for /api/organizations, /api/accounts, /api/positions. **Wiki**: POST /api/wiki/ask, /api/wiki/search, /api/wiki/reindex. **Sharing**: POST /api/results/{id}/share, GET /api/results/shared/{token}. WebSocket at /ws for real-time interview.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "api",
        "endpoints",
        "rest",
        "routes",
        "interview",
        "results",
        "feedback",
        "wiki",
        "crud"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_frontend_001",
      "question": "How is the frontend structured?",
      "answer": "Frontend uses Next.js 14 with App Router in frontend/src/app: **Pages**: / (Dashboard), /active (Quick Start), /interview (Live Interview), /admin/results (Feedback Page), /share/[token] (Public Result). **Components**: CandidateView.tsx, AdminDashboard.tsx, CodeEditor.tsx, ResultsHistory.tsx, ShareModal.tsx. **Styling**: Tailwind CSS with EPAM-inspired dark theme (black, #39FF14 accent, #00E5FF secondary). **State**: React hooks + sessionStorage for reload protection.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/app/",
        "frontend/src/components/"
      ],
      "keywords": [
        "frontend",
        "react",
        "next.js",
        "components",
        "pages",
        "tailwind",
        "ui",
        "dashboard",
        "interview"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_ports_001",
      "question": "What ports does the application use?",
      "answer": "Standard port configuration: **Frontend**: localhost:3000 (Next.js dev server). **Backend**: localhost:8000 (FastAPI/Uvicorn). For production, backend runs on 0.0.0.0:8000 (Render deployment uses PORT env var). If port conflicts occur, kill existing processes: 'Get-Process -Name node | Stop-Process -Force' for frontend, 'Get-Process -Name python | Stop-Process -Force' for backend. CORS is configured to allow frontend origin.",
      "category": "Configuration",
      "code_refs": [
        "backend/main.py",
        "frontend/package.json"
      ],
      "keywords": [
        "ports",
        "3000",
        "8000",
        "localhost",
        "cors",
        "configuration",
        "network",
        "server",
        "deployment"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_session_001",
      "question": "How are interview sessions managed?",
      "answer": "Sessions are tracked in interview_sessions.json with statuses: pending, active, completed, expired, abandoned. Key fields: session_id, candidate_name, language, duration_minutes, question_categories. Session lifecycle: 1) Created via quick-start or position flow. 2) Becomes 'active' when candidate connects. 3) Ends as 'completed' (admin ended) or 'abandoned' (admin clicked abandon). Cleanup endpoint marks sessions >2 hours old as 'expired'. Active sessions show in Results page with Rejoin button.",
      "category": "Session Management",
      "code_refs": [
        "backend/models/interview_sessions.json",
        "backend/main.py"
      ],
      "keywords": [
        "session",
        "management",
        "status",
        "active",
        "expired",
        "completed",
        "cleanup",
        "tracking"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_sharing_001",
      "question": "How does result sharing work?",
      "answer": "Result sharing allows creating public links for approved feedback: 1) Click 'Share' on approved result in Results page. 2) Creates share_token in result file (format: share_{random_hex}). 3) Shows modal with: shareable URL and QR code (using qrcode.react). 4) Public page at /share/[token] displays: candidate name, date, feedback summary (rendered as Markdown). No authentication required for public view. Tokens are permanent unless result is deleted.",
      "category": "Sharing",
      "code_refs": [
        "frontend/src/components/ShareModal.tsx",
        "frontend/src/app/share/[token]/page.tsx"
      ],
      "keywords": [
        "share",
        "public link",
        "qr code",
        "feedback",
        "token",
        "shareable",
        "url",
        "publish"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_codeeditor_001",
      "question": "How does the code editor work for coding questions?",
      "answer": "The code editor uses Monaco Editor (same as VS Code) via @monaco-editor/react: 1) Displays starter_code from question definition. 2) Language is set based on interview language (python/java). 3) Real-time sync: candidate keystrokes are sent to admin via WebSocket code_update messages. 4) Syntax highlighting, IntelliSense, error markers. 5) Code is captured on submit for evaluation. Editor supports themes and is configured in CodeEditor.tsx component.",
      "category": "Code Editor",
      "code_refs": [
        "frontend/src/components/CodeEditor.tsx"
      ],
      "keywords": [
        "code editor",
        "monaco",
        "coding question",
        "syntax",
        "real-time",
        "sync",
        "programming"
      ],
      "created_at": "2025-12-14T08:00:00.000000"
    },
    {
      "id": "wiki_reload_001",
      "question": "How does reload protection work for admin dashboard?",
      "answer": "Admin dashboard has reload protection to prevent accidental session loss: 1) beforeunload event shows browser confirmation if interview is active. 2) sessionStorage tracks admin_session_{id} flag. 3) On reload, if flag exists, user is redirected to home page instead of restarting the session. 4) Rejoin functionality: Active sessions appear in Results page with 'Rejoin' button that clears the flag and navigates back. This prevents the issue of orphaned sessions from accidental page refreshes.",
      "category": "Admin Features",
      "code_refs": [
        "frontend/src/components/AdminDashboard.tsx"
      ],
      "keywords": [
        "reload",
        "protection",
        "beforeunload",
        "session",
        "rejoin",
        "admin",
        "accidental",
        "refresh"
      ],
      "created_at": "2025-12-14T08:00:00.000000",
      "_match_score": 0.6904166666666667
    },
    {
      "id": "wiki_3421e841",
      "question": "how is evaluation of a candidate take place here",
      "answer": "Candidate evaluation within the AI Interview Platform occurs in two primary stages. Initially, a candidate's profile is matched against a job position using the `calculate_candidate_match_score` function in `backend/main.py`. This function assesses skill alignment – including partial matching (e.g., recognizing Django as a Python skill) – and experience level, resulting in a percentage match score. This score represents how well the candidate's background fits the role's requirements. Subsequently, the `Evaluator` class (defined in `backend/evaluation/evaluator.py`) assesses the candidate's *responses* to interview questions. This evaluation employs keyword coverage (checking for relevant terms), completeness scoring (assessing how thoroughly the question was answered), and leverages a Large Language Model (LLM) for more sophisticated, nuanced understanding. The `Evaluator` aggregates these factors into an overall score, also ranging from 0-100. These two scores – the profile match score and the response evaluation score – are likely combined (though the combination logic isn't shown in the provided context) to provide a holistic candidate evaluation.",
      "category": "General",
      "code_refs": [
        "backend/main.py",
        "backend/evaluation/evaluator.py"
      ],
      "keywords": [
        "evaluation",
        "candidate",
        "scoring",
        "matching",
        "skills",
        "llm",
        "keywords",
        "completeness"
      ],
      "created_at": "2025-12-14T14:33:22.692767",
      "auto_generated": true
    },
    {
      "id": "wiki_api_quickstart",
      "question": "How does the Quick Start API endpoint work?",
      "answer": "The `POST /api/interviews/quick-start` endpoint creates an interview session instantly without pre-configured positions. **Request Body**: `{candidate_name, candidate_email, candidate_experience, language (python/java), duration_minutes, question_categories, candidate_account, candidate_role}`. **Process**: 1) Generates unique session_id with timestamp format `session_YYYYMMDD_HHMMSS`. 2) Stores session in `interview_sessions.json` with status='pending'. 3) Loads questions from `questions/{language}.json` based on selected categories. 4) Returns `{session_id, status, redirect_url}`. **Question Categories**: coding, conceptual, system_design, problem_solving - each with enabled flag, count, and difficulty. Admin then navigates to `/interview?view=admin&session_id=...` to start.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "quick start",
        "api",
        "endpoint",
        "create session",
        "start interview",
        "post",
        "instant",
        "adhoc",
        "begin",
        "initiate",
        "launch",
        "new interview",
        "session creation"
      ],
      "created_at": "2025-12-14T14:54:00.000000"
    },
    {
      "id": "wiki_api_active_sessions",
      "question": "How do I get a list of active interview sessions?",
      "answer": "The `GET /api/sessions/active` endpoint returns all in-progress interview sessions for admin rejoin functionality. **Response**: `{sessions: [{session_id, candidate_name, language, created_at, duration_minutes, status, candidate_account, candidate_role}]}`. **Filtering Logic**: 1) Only includes sessions with status='active' or 'pending'. 2) Excludes sessions older than 6 hours (stale filter). 3) Excludes sessions where candidate_name='Unknown' (incomplete sessions). 4) Sorted by created_at descending (newest first). This endpoint powers the 'Active Sessions' section in the Results page, showing sessions that can be rejoined.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "active sessions",
        "list",
        "get",
        "in progress",
        "ongoing",
        "current",
        "live",
        "rejoin",
        "pending",
        "running interviews",
        "session list"
      ],
      "created_at": "2025-12-14T14:54:00.000000"
    },
    {
      "id": "wiki_api_cleanup",
      "question": "How does session cleanup work? How to remove stale sessions?",
      "answer": "The `POST /api/sessions/cleanup` endpoint marks old abandoned sessions as expired. **Behavior**: 1) Scans all sessions in `interview_sessions.json`. 2) For each session with status='active' or 'pending' and no `ended_at`. 3) If `created_at` is older than 2 hours, marks it as `status='expired'`, sets `ended_at=now()`, `end_reason='auto_cleanup'`. 4) Returns `{status: 'success', cleaned_count: N}`. **Use Case**: Admin clicks 'Clean Up Stale' button in Results page to remove orphaned sessions from failed browser closes or network issues. Does NOT delete data, only updates status.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "cleanup",
        "stale",
        "expired",
        "remove",
        "delete",
        "old sessions",
        "orphaned",
        "abandoned",
        "clear",
        "purge",
        "housekeeping",
        "maintenance"
      ],
      "created_at": "2025-12-14T14:54:00.000000"
    },
    {
      "id": "wiki_api_abandon",
      "question": "How can an admin abandon or cancel an interview session?",
      "answer": "The `POST /api/sessions/{session_id}/abandon` endpoint allows admin to manually cancel a specific session. **Process**: 1) Looks up session in `interview_sessions.json` by session_id. 2) If not found, returns 404. 3) Updates: `status='abandoned'`, `ended_at=now()`, `end_reason='admin_abandoned'`. 4) Saves to file and returns `{status: 'success', session_id}`. **UI**: Each active session card in Results page has a red 'Abandon' button. Clicking prompts for confirmation, then calls this endpoint. Abandoned sessions no longer appear in active list but data is preserved for audit.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "abandon",
        "cancel",
        "stop",
        "terminate",
        "end session",
        "abort",
        "quit",
        "close session",
        "discard",
        "remove session",
        "kill"
      ],
      "created_at": "2025-12-14T14:54:00.000000"
    },
    {
      "id": "wiki_api_websocket",
      "question": "How does the WebSocket endpoint work for live interviews?",
      "answer": "The `WebSocket /ws` endpoint enables real-time bidirectional communication during interviews. **Connection**: `ws://localhost:8000/ws?view=candidate` or `?view=admin&session_id=X&lang=Y`. **Message Types**: 1) `init_session` - Start new session with candidate info. 2) `answer` - Candidate submits response. 3) `code_update` - Real-time code sync to admin. 4) `next_question` - Server sends next question. 5) `followup` - AI-generated follow-up question. 6) `expert_action` - Admin approve/edit/override in expert mode. 7) `interview_end` - Session completion. **ConnectionManager**: Tracks active connections per view, broadcasts messages, handles reconnection with session state restoration from `interview_sessions.json`.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "websocket",
        "ws",
        "realtime",
        "live",
        "socket",
        "connection",
        "bidirectional",
        "sync",
        "messages",
        "streaming",
        "push",
        "events",
        "subscribe"
      ],
      "created_at": "2025-12-14T14:54:00.000000"
    },
    {
      "id": "wiki_api_results_list",
      "question": "How do I get all interview results? How to fetch results list?",
      "answer": "The `GET /api/admin/results` endpoint returns all completed interview results. **Response**: `{results: [{session_id, candidate_name, candidate_account, candidate_role, language, date, status (completed/pending_review/published), score, feedback_status, share_token}]}`. **Data Source**: Scans `candidate_results/` folder, reads all `*_result.json` files, extracts latest interview from each. **Sorting**: By date descending. **Statuses**: 1) `pending_review` - Feedback not yet generated. 2) `completed` - Feedback generated but not approved. 3) `published` - Feedback approved and shareable. Used by ResultsHistory.tsx component with pagination (10 per page).",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py",
        "frontend/src/components/ResultsHistory.tsx"
      ],
      "keywords": [
        "results",
        "list",
        "get",
        "all results",
        "interview history",
        "completed",
        "fetch",
        "view results",
        "past interviews",
        "history"
      ],
      "created_at": "2025-12-14T14:55:00.000000"
    },
    {
      "id": "wiki_api_feedback_generate",
      "question": "How does feedback generation work? How to create interview report?",
      "answer": "The `POST /api/feedback/generate` endpoint uses AI to create interview reports. **Request**: `{session_id, feedback_type ('detailed'/'short')}`. **Process**: 1) Loads interview transcript from result file. 2) Calls Feedback Agent (agents/feedback_agent.py) with transcript and scores. 3) LLM generates structured report with: summary, strengths, weaknesses, recommendation. 4) Returns `{status, feedback_content}`. **Types**: 'detailed' = formal EPAM-style with sections. 'short' = bullet points only. **Important**: Feedback is NOT saved automatically - admin must review and approve via /api/feedback/approve.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py",
        "backend/agents/feedback_agent.py"
      ],
      "keywords": [
        "feedback",
        "generate",
        "report",
        "create",
        "ai",
        "summary",
        "llm",
        "transcript",
        "strengths",
        "weaknesses",
        "recommendation"
      ],
      "created_at": "2025-12-14T14:55:00.000000"
    },
    {
      "id": "wiki_api_feedback_approve",
      "question": "How do I approve and publish interview feedback?",
      "answer": "The `POST /api/feedback/approve` endpoint saves and publishes reviewed feedback. **Request**: `{session_id, feedback_content (edited text)}`. **Process**: 1) Finds result file for session. 2) Updates: `feedback_report.content = feedback_content`, `feedback_report.status = 'APPROVED'`, `feedback_report.approved_at = now()`. 3) Sets result `status = 'published'`. 4) Saves to file. 5) Returns `{status: 'success'}`. **Important**: Admin can edit feedback_content before approving (review step). Once approved, feedback is visible on public share page. Cannot un-approve - use reject for corrections.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "approve",
        "publish",
        "feedback",
        "confirm",
        "save",
        "finalize",
        "submit",
        "release",
        "make public",
        "accept"
      ],
      "created_at": "2025-12-14T14:55:00.000000"
    },
    {
      "id": "wiki_api_feedback_reject",
      "question": "How can I reject or cancel feedback for an interview?",
      "answer": "The `POST /api/feedback/reject` endpoint marks feedback as rejected with a reason. **Request**: `{session_id, rejection_reason}`. **Process**: 1) Validates session_id and loads result file. 2) Updates: `feedback_report.status = 'REJECTED'`, `feedback_report.rejection_reason = reason`, `feedback_report.rejected_at = now()`. 3) Saves and returns `{status: 'success'}`. **Use Cases**: 1) Incorrect/inappropriate AI-generated content. 2) Wrong candidate matched. 3) Interview was test/practice. **UI**: Red 'Reject' button in feedback modal prompts for reason via dialog.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "reject",
        "cancel",
        "decline",
        "refuse",
        "deny",
        "feedback rejection",
        "discard feedback",
        "not approve",
        "reason"
      ],
      "created_at": "2025-12-14T14:55:00.000000"
    },
    {
      "id": "wiki_api_result_status",
      "question": "How to check the status of a specific interview result?",
      "answer": "The `GET /api/results/{session_id}/status` endpoint returns status of a specific result. **Response**: `{session_id, candidate_name, status, feedback_status, score, has_transcript, share_token}`. **Statuses**: `pending_review` (needs feedback), `completed` (feedback generated, not approved), `published` (approved and public). **Feedback Statuses**: `PENDING`, `APPROVED`, `REJECTED`. **Use Case**: Polling after feedback generation to check if ready. Also used by share page to verify token validity before displaying.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "status",
        "check",
        "result",
        "specific",
        "single",
        "lookup",
        "find",
        "get one",
        "fetch status"
      ],
      "created_at": "2025-12-14T14:55:00.000000"
    },
    {
      "id": "wiki_api_organizations",
      "question": "How do I manage organizations in the system?",
      "answer": "The `/api/organizations` endpoints provide CRUD operations for top-level organization management. **GET /api/organizations**: Returns list of all orgs `[{id, name, industry, accounts_count}]`. **POST /api/organizations**: Create new org `{name, industry}`. **GET /api/organizations/{id}**: Get single org details with nested accounts. **PUT /api/organizations/{id}**: Update org properties. **DELETE /api/organizations/{id}**: Remove org (cascades to accounts). **Data Storage**: `models/organizations.json`. **Hierarchy**: Organization → Accounts → Positions → Candidates. Used by main dashboard for org selector dropdown.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py",
        "backend/models/organizations.json"
      ],
      "keywords": [
        "organizations",
        "org",
        "company",
        "crud",
        "create",
        "update",
        "delete",
        "list",
        "manage",
        "enterprise",
        "client"
      ],
      "created_at": "2025-12-14T14:56:00.000000"
    },
    {
      "id": "wiki_api_accounts",
      "question": "How do I manage accounts under an organization?",
      "answer": "The `/api/accounts` endpoints manage client accounts within organizations. **GET /api/accounts**: List all accounts with filters `?org_id=X`. **POST /api/accounts**: Create account `{name, org_id, description, branding}`. **GET /api/accounts/{id}**: Get account with positions. **PUT /api/accounts/{id}**: Update account. **DELETE /api/accounts/{id}**: Remove account. **GET /api/accounts/{id}/positions**: List positions under account. **Data Storage**: `models/accounts.json`. **Example**: Uber (org) → Uber Maps Team (account) → Senior Python Developer (position). Used for filtering in dashboard sidebar.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py",
        "backend/models/accounts.json"
      ],
      "keywords": [
        "accounts",
        "account",
        "team",
        "department",
        "crud",
        "client",
        "manage",
        "create account",
        "list accounts"
      ],
      "created_at": "2025-12-14T14:56:00.000000"
    },
    {
      "id": "wiki_api_positions",
      "question": "How do I manage job positions and their interview configs?",
      "answer": "The `/api/positions` endpoints manage job positions with interview configuration. **GET /api/positions**: List all positions with filters. **POST /api/positions**: Create position `{title, account_id, jd_id, required_skills[], experience_level, interview_config{duration, categories, language}}`. **GET /api/positions/{id}**: Get position with matched candidates. **PUT /api/positions/{id}**: Update position. **GET /api/positions/{id}/candidates**: List candidates sorted by match score. **POST /api/positions/{id}/start-interview**: Begin interview for specific candidate. **Data Storage**: `models/positions.json`. Each position links to a JD from `models/job_descriptions/`.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py",
        "backend/models/positions.json"
      ],
      "keywords": [
        "positions",
        "job",
        "role",
        "vacancy",
        "crud",
        "interview config",
        "jd",
        "job description",
        "hiring",
        "opening"
      ],
      "created_at": "2025-12-14T14:56:00.000000"
    },
    {
      "id": "wiki_api_share_create",
      "question": "How do I create a shareable link for interview results?",
      "answer": "The `POST /api/results/{session_id}/share` endpoint generates a public share token. **Process**: 1) Validates session exists and feedback is APPROVED. 2) If no share_token exists, generates one: `share_{8_char_hex}`. 3) Saves token to result file. 4) Returns `{share_token, share_url}`. **URL Format**: `https://domain.com/share/{token}`. **Requirements**: Only published (approved) results can be shared. **UI**: 'Share' button appears next to published results, opens ShareModal with QR code. Token is permanent - same link works forever unless result is deleted.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py",
        "frontend/src/components/ShareModal.tsx"
      ],
      "keywords": [
        "share",
        "link",
        "public",
        "create link",
        "generate url",
        "token",
        "shareable",
        "send",
        "distribute",
        "qr code"
      ],
      "created_at": "2025-12-14T14:56:00.000000",
      "_match_score": 0.72
    },
    {
      "id": "wiki_api_share_view",
      "question": "How does the public share page work for viewing results?",
      "answer": "The `GET /api/results/shared/{token}` endpoint returns public result data. **Response**: `{candidate_name, position, account, date, feedback_content, score}`. **Validation**: 1) Looks up token in all result files. 2) If not found or feedback not approved, returns 404. 3) Only returns approved feedback content - no transcript or internal scores. **Frontend**: `/share/[token]/page.tsx` renders the public view with: candidate info header, feedback as Markdown (react-markdown), date, overall recommendation. No authentication required. Mobile-responsive design with print-friendly layout.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py",
        "frontend/src/app/share/[token]/page.tsx"
      ],
      "keywords": [
        "share",
        "public",
        "view",
        "token",
        "open",
        "access",
        "external",
        "third party",
        "candidate share",
        "recruiter link"
      ],
      "created_at": "2025-12-14T14:56:00.000000"
    },
    {
      "id": "wiki_core_interview_controller",
      "question": "What is the InterviewController and how does it manage interview flow?",
      "answer": "The `InterviewController` class (core/interview_controller.py) is the brain of interview orchestration. **Responsibilities**: 1) Manages interview state machine: WAITING → ACTIVE → EVALUATION → COMPLETED. 2) Loads questions from question bank based on session config. 3) Tracks current_question_index and answered_questions. 4) Coordinates with Evaluator for response scoring. 5) Requests follow-up questions from GeminiClient when needed. 6) Handles Expert Mode: queues pending_followup for admin approval. 7) Stores transcript incrementally. **Key Methods**: `start_interview()`, `process_answer()`, `get_next_question()`, `end_interview()`. Instantiated per session, state persisted to interview_sessions.json.",
      "category": "Core Modules",
      "code_refs": [
        "backend/core/interview_controller.py"
      ],
      "keywords": [
        "interview controller",
        "flow",
        "orchestration",
        "state machine",
        "brain",
        "manager",
        "control",
        "logic",
        "process"
      ],
      "created_at": "2025-12-14T14:57:00.000000"
    },
    {
      "id": "wiki_core_evaluator",
      "question": "How does the Evaluator class score candidate responses?",
      "answer": "The `Evaluator` class (evaluation/evaluator.py) scores interview responses using multiple criteria. **Scoring Components**: 1) **Keyword Coverage** (weight varies): Checks `expected_keywords` from question, calculates match percentage. 2) **Factual Correctness** (for boolean questions): Binary 0/100 based on correct answer. 3) **Completeness**: LLM assesses how thoroughly question was answered. 4) **Technical Accuracy**: LLM validates technical claims in response. 5) **Clarity & Depth**: Quality of explanation. **Process**: `evaluate_response(question, response)` → applies rubric weights → returns `{score: 0-100, breakdown: {}, feedback: ''}`. Rubric weights are defined per question in question_bank.json.",
      "category": "Core Modules",
      "code_refs": [
        "backend/evaluation/evaluator.py"
      ],
      "keywords": [
        "evaluator",
        "scoring",
        "grading",
        "assessment",
        "rubric",
        "keywords",
        "completeness",
        "accuracy",
        "marks",
        "points"
      ],
      "created_at": "2025-12-14T14:57:00.000000"
    },
    {
      "id": "wiki_core_gemini_client",
      "question": "How does the GeminiClient integrate with Google's AI for generation?",
      "answer": "The `GeminiClient` class (llm/gemini_client.py) wraps Google Gemini API for AI features. **Model**: Uses `gemma-3-27b-it` (configurable). **Key Methods**: 1) `generate_followup(question, response, quality)` → Creates contextual follow-up questions. 2) `evaluate_response(question, response)` → Technical accuracy validation. 3) `generate_feedback(transcript, scores)` → Full interview report. **Configuration**: API key via `GEMINI_API_KEY` env var. Temperature: 0.7 for generation, 0.3 for evaluation. Max tokens: 1024 for followups, 4096 for feedback. **Error Handling**: Retries on rate limits, falls back to generic questions on failure.",
      "category": "Core Modules",
      "code_refs": [
        "backend/llm/gemini_client.py"
      ],
      "keywords": [
        "gemini",
        "client",
        "llm",
        "ai",
        "google",
        "api",
        "generation",
        "model",
        "integration",
        "artificial intelligence"
      ],
      "created_at": "2025-12-14T14:57:00.000000"
    },
    {
      "id": "wiki_core_feedback_agent",
      "question": "What is the Feedback Agent and how does it create reports?",
      "answer": "The `FeedbackAgent` (agents/feedback_agent.py) generates structured interview reports. **Input**: Interview transcript (Q&A pairs), per-question scores, candidate info. **Process**: 1) Constructs prompt with transcript and scoring context. 2) Calls GeminiClient with feedback generation prompt. 3) Parses LLM response into structured sections. **Output Types**: 'detailed' = Formal EPAM-style report with: Executive Summary, Technical Assessment, Strengths (3-5 bullets), Areas for Improvement, Recommendation (Hire/No Hire/Maybe). 'short' = Condensed bullet points. **Template**: Uses Jinja2-style prompts in prompts/feedback_template.txt.",
      "category": "Core Modules",
      "code_refs": [
        "backend/agents/feedback_agent.py"
      ],
      "keywords": [
        "feedback agent",
        "report",
        "summary",
        "generation",
        "strengths",
        "weaknesses",
        "recommendation",
        "hire",
        "assessment"
      ],
      "created_at": "2025-12-14T14:57:00.000000"
    },
    {
      "id": "wiki_core_connection_manager",
      "question": "How does ConnectionManager handle WebSocket connections?",
      "answer": "The `ConnectionManager` class (in main.py) manages real-time WebSocket connections. **Structure**: Maintains `active_connections: Dict[str, Dict[str, WebSocket]]` mapping session_id → {view: websocket}. **Key Methods**: 1) `connect(session_id, view, websocket)` → Registers connection, removes old if exists. 2) `disconnect(session_id, view)` → Cleans up on close. 3) `send_to_view(session_id, view, message)` → Sends JSON to specific view. 4) `broadcast(session_id, message)` → Sends to both candidate and admin. **Reconnection**: When websocket reconnects, restores interview state from interview_sessions.json and replays last question.",
      "category": "Core Modules",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "connection manager",
        "websocket",
        "connections",
        "realtime",
        "broadcast",
        "send",
        "receive",
        "socket",
        "live"
      ],
      "created_at": "2025-12-14T14:57:00.000000"
    },
    {
      "id": "wiki_core_question_manager",
      "question": "How does the QuestionManager select and serve questions?",
      "answer": "The `QuestionManager` (core/question_manager.py) handles question selection and sequencing. **Loading**: 1) Regular mode: Loads from position's linked question_bank.json. 2) Quick Start: Loads from questions/{language}.json. **Selection Algorithm**: 1) Filters by enabled categories (coding, conceptual, system_design, problem_solving). 2) Filters by difficulty level. 3) Randomizes within category, respects count per category. **Serving**: `get_next_question()` returns question dict with: id, type, text, topic, expected_keywords, evaluation_rubric. Tracks asked_question_ids to prevent repeats. Supports `get_question_by_id()` for follow-up context.",
      "category": "Core Modules",
      "code_refs": [
        "backend/core/question_manager.py"
      ],
      "keywords": [
        "question manager",
        "questions",
        "selection",
        "loading",
        "bank",
        "serve",
        "next question",
        "sequence",
        "category"
      ],
      "created_at": "2025-12-14T14:57:00.000000"
    },
    {
      "id": "wiki_strategy_factory",
      "question": "What is the Strategy Factory and how does it select follow-up strategies?",
      "answer": "The `StrategyFactory` (strategies/strategy_factory.py) implements the Strategy Pattern for dynamic follow-up selection. **Purpose**: Chooses the best follow-up approach based on candidate performance. **Available Strategies**: 1) `DepthFocusedStrategy` - Digs deeper on weak areas. 2) `BreadthFocusedStrategy` - Explores new topics. 3) `ClarificationStrategy` - Asks for specifics on vague answers. **Selection Logic**: `select_strategy(response_quality, topic_coverage)` → If quality < 50%: depth. If coverage < 70%: breadth. If vague: clarification. **Interface**: All strategies implement `generate_followup(context)` method. Easily extensible for new strategies like ProbeStrategy or ChallengeStrategy.",
      "category": "Core Modules",
      "code_refs": [
        "backend/strategies/strategy_factory.py"
      ],
      "keywords": [
        "strategy",
        "factory",
        "pattern",
        "follow-up",
        "selection",
        "depth",
        "breadth",
        "adaptive",
        "dynamic"
      ],
      "created_at": "2025-12-14T14:58:00.000000"
    },
    {
      "id": "wiki_strategy_depth",
      "question": "How does the Depth Focused Strategy work for weak areas?",
      "answer": "The `DepthFocusedStrategy` (strategies/depth_focused.py) probes deeper when candidate shows knowledge gaps. **Trigger**: Response quality score < 50% or specific topic weakness detected. **Behavior**: 1) Analyzes which concepts were missed/incorrect. 2) Generates follow-up on same topic at slightly lower difficulty. 3) Asks 'why' and 'how' questions to verify understanding. **Example**: If candidate incorrectly explains Python GIL, follow-up might be: 'Can you elaborate on what happens when two threads try to execute Python bytecode simultaneously?' **Goal**: Distinguish between gap vs total unfamiliarity.",
      "category": "Core Modules",
      "code_refs": [
        "backend/strategies/depth_focused.py"
      ],
      "keywords": [
        "depth",
        "deep dive",
        "probe",
        "weakness",
        "gap",
        "drill down",
        "follow up",
        "understand better"
      ],
      "created_at": "2025-12-14T14:58:00.000000"
    },
    {
      "id": "wiki_strategy_breadth",
      "question": "How does the Breadth Focused Strategy explore more topics?",
      "answer": "The `BreadthFocusedStrategy` (strategies/breadth_focused.py) moves to new topics when current one is well-covered. **Trigger**: Response quality > 75% AND topic coverage high. **Behavior**: 1) Checks topics_covered list from session. 2) Selects next topic from available categories not yet tested. 3) Generates transition question bridging current and new topic. **Example**: After strong Python OOP answer, might transition: 'You mentioned inheritance - how would you design a class hierarchy for a REST API client?' **Goal**: Maximize topic coverage within time limit, avoid redundant questions.",
      "category": "Core Modules",
      "code_refs": [
        "backend/strategies/breadth_focused.py"
      ],
      "keywords": [
        "breadth",
        "wide",
        "explore",
        "new topic",
        "coverage",
        "variety",
        "different areas",
        "move on"
      ],
      "created_at": "2025-12-14T14:58:00.000000"
    },
    {
      "id": "wiki_scoring_algorithms",
      "question": "What scoring algorithms are used for different question types?",
      "answer": "The scoring algorithms (evaluation/scoring_algorithms.py) provide type-specific evaluation. **True/False & Yes/No**: Binary - 0 or 100 based on correct answer flag, weighted by `deterministic_answer.weight`. **Multiple Choice**: `(correct_selected - incorrect_selected) / total_correct * 100`. **Coding**: Test case pass rate + efficiency score + code quality rubric. **Open Ended**: LLM-based assessment with: keyword_coverage (partial match allowed), completeness, technical_accuracy, clarity. **Aggregation**: Per-question rubric weights sum to 1.0. Final score = Σ(component_score × component_weight). All scores normalized to 0-100 range.",
      "category": "Core Modules",
      "code_refs": [
        "backend/evaluation/scoring_algorithms.py"
      ],
      "keywords": [
        "scoring",
        "algorithm",
        "calculation",
        "formula",
        "weight",
        "rubric",
        "points",
        "grading logic",
        "evaluation method"
      ],
      "created_at": "2025-12-14T14:58:00.000000"
    },
    {
      "id": "wiki_data_models_overview",
      "question": "What data models are used and where are they stored?",
      "answer": "All data is stored as JSON files in `backend/models/`. **Core Models**: 1) `organizations.json` - Top-level company records. 2) `accounts.json` - Teams/departments under orgs. 3) `positions.json` - Job openings with interview config. 4) `interview_sessions.json` - All session metadata and state. 5) `question_bank.json` - Full question library with rubrics. 6) `wiki.json` - This knowledge base. **Dynamic Data**: `candidate_results/{name}+{date}_result.json` - Per-candidate interview records. `resumes/resumes.json` - Parsed candidate profiles. **No Database**: Pure file-based for simplicity, easily migrated to PostgreSQL later.",
      "category": "Data Storage",
      "code_refs": [
        "backend/models/"
      ],
      "keywords": [
        "data models",
        "storage",
        "json",
        "files",
        "database",
        "persistence",
        "schema",
        "structure",
        "where stored"
      ],
      "created_at": "2025-12-14T14:58:00.000000"
    },
    {
      "id": "wiki_search_algorithm",
      "question": "How does wiki search work for finding relevant answers?",
      "answer": "Wiki search uses multi-layer matching in `/api/wiki/search`. **Layer 1 - Exact Match**: Direct keyword match in entry keywords array. **Layer 2 - Synonym Expansion**: Uses `semantic_index.synonym_mappings` to expand query terms (e.g., 'grading' → 'evaluation'). **Layer 3 - Pattern Matching**: Matches `layman_patterns` like 'how does * work' to topic categories. **Layer 4 - Topic Lookup**: Uses `indexed_topics` to find related entries. **Scoring**: Each layer contributes to relevance score. Top 5 entries returned sorted by score. **Cache**: LRU cache on frequent queries. If no match, `/api/wiki/ask` triggers LLM generation of new answer which is auto-added to wiki.",
      "category": "Core Modules",
      "code_refs": [
        "backend/main.py",
        "backend/models/wiki.json"
      ],
      "keywords": [
        "search",
        "find",
        "lookup",
        "match",
        "semantic",
        "query",
        "relevant",
        "answer",
        "wiki search"
      ],
      "created_at": "2025-12-14T14:58:00.000000"
    },
    {
      "id": "wiki_data_session_structure",
      "question": "What is the structure of an interview session?",
      "answer": "Interview sessions are stored in `interview_sessions.json`. **Fields**: `session_id` (format: session_YYYYMMDD_HHMMSS), `created_at`, `expires_at`, `status` (pending/active/completed/expired/abandoned), `mode` (quick_start/regular), `language` (python/java), `duration_minutes`, `expert_mode` (boolean), `question_categories` (object with coding/conceptual/system_design/problem_solving each having enabled/count/difficulty), `candidate_name`, `candidate_info` ({name, email, experience_years}), `candidate_account`, `candidate_role`, `ended_at`, `ended_by` (admin/system), `end_reason`. **Lifecycle**: pending → active (on candidate connect) → completed/abandoned/expired.",
      "category": "Data Storage",
      "code_refs": [
        "backend/models/interview_sessions.json"
      ],
      "keywords": [
        "session",
        "structure",
        "format",
        "fields",
        "schema",
        "interview session",
        "data",
        "json structure"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_data_question_types",
      "question": "What types of questions are supported in the question bank?",
      "answer": "The system supports 5 question types, each with specific evaluation: **1) true_false_with_explanation**: Binary answer + explanation. `deterministic_answer.correct_value` defines correct. **2) yes_no_with_explanation**: Same as true/false. **3) multiple_choice_with_explanation**: Multiple correct options. `correct_options: ['A','C']`. **4) open_ended**: Free-form response, LLM-evaluated. **5) coding**: Code solution with `starter_code`, `test_cases`, `language`. Each has `evaluation_rubric` with weighted criteria. Types are in `question.type` field. Question bank categorizes by: `category` (coding/conceptual/system_design/problem_solving), `difficulty` (easy/medium/hard), `experience_levels` ([junior/mid/senior/lead]).",
      "category": "Data Storage",
      "code_refs": [
        "backend/models/question_bank.json",
        "backend/questions/python.json"
      ],
      "keywords": [
        "question types",
        "true false",
        "multiple choice",
        "coding",
        "open ended",
        "categories",
        "difficulty",
        "format"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_data_result_format",
      "question": "What is the format of interview result files?",
      "answer": "Results are stored in `candidate_results/{name}+{date}_result.json`. **Structure**: `{candidate_name, candidate_info: {name, email, experience}, interviews: [{session_id, date, language, account, role, questions_answered, scores: [], transcript: [{question, response, score, timestamp}], overall_score, duration_minutes}], feedback_report: {status (PENDING/APPROVED/REJECTED), content, type (detailed/short), generated_at, approved_at, rejection_reason}, share_token}`. **Multiple Interviews**: Same candidate can have multiple interview records in the `interviews` array. Latest is shown in Results page.",
      "category": "Data Storage",
      "code_refs": [
        "backend/candidate_results/"
      ],
      "keywords": [
        "result",
        "format",
        "structure",
        "transcript",
        "scores",
        "feedback",
        "output",
        "interview record"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_data_question_rubric",
      "question": "How are evaluation rubrics structured for questions?",
      "answer": "Each question has an `evaluation_rubric` object defining scoring criteria. **Standard Fields**: `factual_correctness` (for deterministic answers), `completeness`, `technical_accuracy`, `depth`, `clarity`. **Weights**: Each criterion has `weight` (0.0-1.0, must sum to 1.0) and `criteria` (description for LLM evaluation). **Example**: `{'completeness': {'weight': 0.30, 'criteria': 'Should explain both shallow and deep copy'}, ...}`. **Coding Questions**: Use `correctness`, `efficiency`, `code_quality`, `edge_cases`. Rubrics enable consistent, transparent scoring across all question types.",
      "category": "Data Storage",
      "code_refs": [
        "backend/models/question_bank.json"
      ],
      "keywords": [
        "rubric",
        "evaluation",
        "criteria",
        "weight",
        "scoring",
        "grading criteria",
        "assessment criteria"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_frontend_dashboard",
      "question": "How does the main admin dashboard work?",
      "answer": "The dashboard (`frontend/src/app/page.tsx`) is the landing page for admins. **Sections**: 1) **Sidebar**: Organization/Account selector dropdown, navigation links. 2) **Positions Grid**: Cards for each position under selected account showing title, required skills, interview config. 3) **Candidates List**: Per-position, sorted by match score with 'Start Interview' buttons. 4) **Quick Actions**: 'Quick Start' button for ad-hoc interviews. **State**: Uses React hooks for org/account/position selection. Fetches from `/api/organizations`, `/api/accounts`, `/api/positions`. Responsive design with Tailwind CSS grid.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/app/page.tsx"
      ],
      "keywords": [
        "dashboard",
        "home",
        "main page",
        "admin",
        "landing",
        "positions",
        "candidates",
        "ui"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_frontend_interview_page",
      "question": "How does the live interview page work?",
      "answer": "The interview page (`frontend/src/app/interview/page.tsx`) hosts real-time interviews. **URL**: `/interview?view=admin&session_id=X` or `?view=candidate`. **Components**: Renders `AdminDashboard.tsx` or `CandidateView.tsx` based on `view` param. **WebSocket**: Connects to `/ws` for real-time sync. **Flow**: 1) Loads session data. 2) Displays current question. 3) Candidate submits answer → Admin sees it live. 4) Admin can approve/edit follow-ups (expert mode) or auto-proceed. 5) Timer counts down from interview duration. 6) Admin clicks 'End Interview' to complete.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/app/interview/page.tsx"
      ],
      "keywords": [
        "interview page",
        "live",
        "realtime",
        "session",
        "view",
        "candidate view",
        "admin view"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_frontend_results_page",
      "question": "How does the results/feedback page work?",
      "answer": "The results page (`frontend/src/app/admin/results/page.tsx`) shows interview history and feedback management. **Sections**: 1) **Active Sessions**: Cards for ongoing interviews with 'Rejoin' and 'Abandon' buttons. 2) **Results Table**: Paginated (10/page) list of completed interviews with columns: Candidate, Role/Account, Skill, Date, Status, Actions. **Actions**: 'Review' opens feedback modal, 'View Report' shows published feedback, 'Share' generates QR code link. **Statuses**: Pending Review (yellow), Published (green). Uses `ResultsHistory.tsx` component.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/app/admin/results/page.tsx",
        "frontend/src/components/ResultsHistory.tsx"
      ],
      "keywords": [
        "results",
        "feedback",
        "history",
        "page",
        "table",
        "review",
        "share",
        "publish"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_frontend_candidate_view",
      "question": "What does the candidate see during an interview?",
      "answer": "The `CandidateView.tsx` component provides the candidate-facing interview UI. **Elements**: 1) **Header**: Interview title, timer countdown, language indicator. 2) **Question Panel**: Current question text, type indicator (coding/conceptual). 3) **Answer Area**: Text input for conceptual, Monaco code editor for coding questions. 4) **Submit Button**: Sends answer via WebSocket. 5) **Progress**: Question X of Y indicator. **No Controls**: Candidates cannot skip questions, access previous answers, or control interview flow. Minimal distractions for focused experience.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/components/CandidateView.tsx"
      ],
      "keywords": [
        "candidate",
        "view",
        "interview ui",
        "answer",
        "submit",
        "question display",
        "examinee"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_frontend_admin_dashboard",
      "question": "What controls does an admin have during an interview?",
      "answer": "The `AdminDashboard.tsx` component provides admin controls during live interviews. **Controls**: 1) **Real-time View**: See candidate's answer as they type (including code). 2) **Expert Mode Toggle**: Enable/disable approval step for AI follow-ups. 3) **Approve/Edit/Override**: When expert mode on, review AI question before sending. 4) **Manual Question**: Type custom question anytime. 5) **End Interview**: Complete session, triggers score calculation. 6) **Timer Display**: See remaining time. 7) **Transcript Panel**: Live Q&A history. **Protected**: beforeunload warning prevents accidental page close.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/components/AdminDashboard.tsx"
      ],
      "keywords": [
        "admin",
        "controls",
        "dashboard",
        "expert mode",
        "approve",
        "edit",
        "override",
        "interviewer"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_frontend_code_editor",
      "question": "How does the code editor work for coding questions?",
      "answer": "The `CodeEditor.tsx` component wraps Monaco Editor (VS Code engine). **Features**: 1) Syntax highlighting for Python/Java based on session language. 2) Loads `starter_code` from question as initial value. 3) Real-time sync: Every keystroke sent via WebSocket `code_update` message to admin. 4) Line numbers, error markers, IntelliSense. 5) Dark theme matching app aesthetics. **Configuration**: `@monaco-editor/react` package. Height auto-adjusts. Copy/paste enabled. No execution - code evaluated by LLM for logic/approach.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/components/CodeEditor.tsx"
      ],
      "keywords": [
        "code editor",
        "monaco",
        "coding",
        "syntax",
        "programming",
        "ide",
        "editor",
        "write code"
      ],
      "created_at": "2025-12-14T14:59:00.000000"
    },
    {
      "id": "wiki_ws_message_types",
      "question": "What WebSocket message types are used during interviews?",
      "answer": "WebSocket messages are JSON with `type` field. **Client→Server**: 1) `init_session` - Candidate joins with info. 2) `answer` - Candidate submits response. 3) `code_update` - Real-time code sync. 4) `expert_action` - Admin approve/edit/override. 5) `end_interview` - Admin ends session. **Server→Client**: 1) `session_started` - Confirms connection. 2) `next_question` - New question for candidate. 3) `followup` - AI-generated follow-up. 4) `pending_followup` - Admin review needed (expert mode). 5) `interview_end` - Session completed. 6) `error` - Error message. All messages include `session_id` and `timestamp`.",
      "category": "WebSocket",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "websocket",
        "message",
        "type",
        "event",
        "communication",
        "protocol",
        "format",
        "init",
        "answer",
        "followup"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_config_env",
      "question": "What environment variables and configuration are needed?",
      "answer": "**Required Environment Variables**: 1) `GEMINI_API_KEY` - Google AI API key for LLM features. **Optional**: 2) `PORT` - Backend port (default 8000). 3) `FRONTEND_URL` - CORS origin (default localhost:3000). **Files**: `/backend/config.py` defines: `MAX_FOLLOWUPS_PER_QUESTION` (default 2), `SESSION_TIMEOUT_HOURS` (6), `STALE_SESSION_HOURS` (2), `ITEMS_PER_PAGE` (10). **Frontend**: `.env.local` for `NEXT_PUBLIC_API_URL` (default http://localhost:8000). Production uses Render environment settings.",
      "category": "Configuration",
      "code_refs": [
        "backend/config.py",
        "frontend/.env.local"
      ],
      "keywords": [
        "config",
        "environment",
        "env",
        "variables",
        "settings",
        "api key",
        "port",
        "configuration",
        "setup"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_error_handling",
      "question": "How does error handling work in the application?",
      "answer": "**Backend Errors**: FastAPI HTTPException for API errors with status codes (400 bad request, 404 not found, 500 internal). **WebSocket Errors**: Send `{type: 'error', message: '...'}` to client, log to console. **LLM Errors**: GeminiClient retries 3x on rate limits, falls back to generic response on failure. **Frontend Errors**: Try-catch in API calls, toast notifications for user feedback. **Session Errors**: Auto-reconnect logic for WebSocket disconnect, session state restoration from file. **Validation**: Pydantic models validate request bodies, return 422 on schema mismatch.",
      "category": "Error Handling",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "error",
        "handling",
        "exception",
        "fail",
        "retry",
        "validation",
        "catch",
        "problem",
        "issue"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_frontend_share_modal",
      "question": "How does the ShareModal component work for sharing results?",
      "answer": "The `ShareModal.tsx` component displays shareable link and QR code. **Props**: `isOpen`, `onClose`, `shareUrl`, `candidateName`. **Content**: 1) Modal overlay with dark backdrop. 2) Shareable URL in copyable input field. 3) QR code generated using `qrcode.react` library. 4) 'Copy Link' button with success toast. **Usage**: Opened from ResultsHistory when clicking 'Share' on published result. QR code enables mobile scanning for quick access. URL format: `{origin}/share/{token}`.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/components/ShareModal.tsx"
      ],
      "keywords": [
        "share modal",
        "qr code",
        "link",
        "copy",
        "popup",
        "dialog",
        "share component"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_frontend_quick_start_form",
      "question": "How does the Quick Start form collect candidate information?",
      "answer": "The Quick Start page (`/active/page.tsx`) has a multi-step form. **Step 1 - Interview Config**: Select language (Python/Java), duration (10-60 min), question categories (checkboxes for coding/conceptual/system_design/problem_solving). **Step 2 - Candidate Info**: Name, email, experience years, account (optional), role (optional). **Submission**: Calls `POST /api/interviews/quick-start` with all data. **Response**: Receives session_id, redirects to `/interview?view=admin&session_id=X`. Form uses React useState for field management, validation before submit.",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/app/active/page.tsx"
      ],
      "keywords": [
        "quick start",
        "form",
        "input",
        "fields",
        "candidate info",
        "interview setup",
        "configuration form"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_frontend_feedback_modal",
      "question": "How does the feedback generation modal work?",
      "answer": "The feedback modal in `ResultsHistory.tsx` handles report generation. **Steps**: 1) Click 'Review' on pending result → Opens modal. 2) Select type: 'Detailed Summary' or 'Short Summary'. 3) Click 'Generate Report' → Calls `/api/feedback/generate`. 4) Shows generated feedback in editable textarea. 5) Admin reviews/edits content. 6) Click 'Approve & Publish' or 'Reject'. **States**: `generating` (spinner), `viewingFeedback` (edit mode), `approvalStatus`. Reject prompts for reason via window.prompt().",
      "category": "Frontend",
      "code_refs": [
        "frontend/src/components/ResultsHistory.tsx"
      ],
      "keywords": [
        "feedback modal",
        "generate",
        "review",
        "approve",
        "reject",
        "report modal",
        "popup"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_session_statuses",
      "question": "What are all the possible session statuses and their meanings?",
      "answer": "Sessions can have 5 statuses: 1) **pending** - Created but candidate hasn't connected yet. 2) **active** - Interview in progress, both parties connected. 3) **completed** - Interview ended normally by admin, results saved. 4) **expired** - Auto-marked by cleanup (>2 hours with no activity). 5) **abandoned** - Manually cancelled by admin via 'Abandon' button. **Transitions**: pending→active (on connect), active→completed (on end), pending/active→expired (cleanup), pending/active→abandoned (manual). Only 'completed' sessions appear in results for feedback.",
      "category": "Data Storage",
      "code_refs": [
        "backend/models/interview_sessions.json"
      ],
      "keywords": [
        "status",
        "session status",
        "pending",
        "active",
        "completed",
        "expired",
        "abandoned",
        "state"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_feedback_statuses",
      "question": "What are the feedback report statuses?",
      "answer": "Feedback reports have 3 statuses in `feedback_report.status`: 1) **PENDING** - Feedback not yet generated, or generated but not approved. Result shows 'Review' button. 2) **APPROVED** - Admin approved and published. Result shows 'View Report' and 'Share' buttons. Share link works. 3) **REJECTED** - Admin rejected with reason stored in `rejection_reason`. Result shows status indicator but no share. **Workflow**: PENDING → (generate) → PENDING → (approve) → APPROVED or (reject) → REJECTED. No direct PENDING→REJECTED; must generate first.",
      "category": "Data Storage",
      "code_refs": [
        "backend/candidate_results/"
      ],
      "keywords": [
        "feedback status",
        "pending",
        "approved",
        "rejected",
        "report status",
        "publish status"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_pagination",
      "question": "How does pagination work for results and wiki entries?",
      "answer": "**Results Page**: 10 items per page. State: `resultsPage`, `totalPages = Math.ceil(results.length / ITEMS_PER_PAGE)`. `paginatedResults = results.slice((page-1)*10, page*10)`. Controls: Previous/Next buttons disabled at boundaries. **Wiki API**: `/api/wiki/entries?limit=50&offset=0`. Returns `{entries: [], total, has_more}`. Default limit: 50. **Frontend**: Wiki page uses infinite scroll with 'Load More' button. Both use 1-indexed page numbers for UI, 0-indexed offset for API.",
      "category": "UI Features",
      "code_refs": [
        "frontend/src/components/ResultsHistory.tsx"
      ],
      "keywords": [
        "pagination",
        "paging",
        "pages",
        "next",
        "previous",
        "limit",
        "offset",
        "scroll",
        "load more"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_timer_countdown",
      "question": "How does the interview timer work?",
      "answer": "Interview timer is managed in `AdminDashboard.tsx` and `CandidateView.tsx`. **Setup**: `duration_minutes` from session config converted to seconds. **Display**: MM:SS format, updates every second via `setInterval`. **Warning**: Yellow color at 5 minutes, red at 1 minute. **Expiry**: When timer hits 0, shows 'Time's Up!' alert but doesn't auto-end - admin must click End. **Sync**: Timer starts when WebSocket connects, not session creation. Both views show same time (synced via session start timestamp).",
      "category": "UI Features",
      "code_refs": [
        "frontend/src/components/AdminDashboard.tsx",
        "frontend/src/components/CandidateView.tsx"
      ],
      "keywords": [
        "timer",
        "countdown",
        "time",
        "duration",
        "minutes",
        "clock",
        "remaining time"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_tailwind_theme",
      "question": "What is the visual theme and styling approach?",
      "answer": "The app uses Tailwind CSS with EPAM-inspired dark theme. **Colors**: Background `#0A0A0A` (near-black), cards `#1A1A1A`, borders `#333`. Accent: `#39FF14` (EPAM green) for primary actions. Secondary: `#00E5FF` (cyan) for highlights. **Typography**: Inter font family. **Components**: Rounded corners (rounded-xl), subtle shadows, hover transitions. **Dark Mode Only**: No light mode toggle (removed for consistency). **Responsive**: Uses Tailwind grid and flex for mobile support. Defined in `tailwind.config.js` and `globals.css`.",
      "category": "UI Features",
      "code_refs": [
        "frontend/tailwind.config.js",
        "frontend/src/app/globals.css"
      ],
      "keywords": [
        "theme",
        "styling",
        "css",
        "tailwind",
        "colors",
        "dark mode",
        "design",
        "ui",
        "look feel"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_api_wiki_ask",
      "question": "How does the wiki ask endpoint generate new answers?",
      "answer": "The `POST /api/wiki/ask` endpoint handles questions not in cache. **Request**: `{question: '...'}`. **Process**: 1) First searches existing entries via semantic matching. 2) If no good match (score < 0.5), triggers LLM generation. 3) GeminiClient generates answer using codebase context. 4) Auto-creates new wiki entry with: generated answer, extracted keywords, category 'General', `auto_generated: true`. 5) Saves to wiki.json. **Response**: `{answer, source: 'cache'|'generated', entry_id}`. Enables wiki to learn and grow from user questions.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "wiki ask",
        "generate answer",
        "llm",
        "question",
        "create entry",
        "auto generate",
        "learn"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_api_wiki_reindex",
      "question": "How does wiki reindexing work?",
      "answer": "The `POST /api/wiki/reindex` endpoint rebuilds semantic index. **Process**: 1) Loads all entries from wiki.json. 2) Regenerates `synonym_mappings` from entry keywords. 3) Rebuilds `indexed_topics` grouping entries by category. 4) Updates `layman_patterns` based on question formats. 5) Sets `last_indexed` timestamp. 6) Saves wiki.json. **When to Use**: After bulk entry additions, when search quality degrades, after manual edits. **Response**: `{status: 'success', entries_indexed: N, topics: [...]}`. Improves search accuracy for semantic queries.",
      "category": "API Endpoints",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "reindex",
        "rebuild",
        "refresh",
        "update index",
        "wiki maintenance",
        "search index"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_security_cors",
      "question": "How is CORS and security handled?",
      "answer": "**CORS**: FastAPI CORSMiddleware allows `origins=['http://localhost:3000', FRONTEND_URL]`. Methods: GET, POST, PUT, DELETE, OPTIONS. Headers: Content-Type, Authorization. **No Auth Currently**: MVP has no authentication (in backlog). **Rate Limiting**: None implemented yet. **Input Validation**: Pydantic models validate all request bodies. **XSS Prevention**: React auto-escapes, no dangerouslySetInnerHTML (except ReactMarkdown for feedback). **File Access**: Only JSON files in models/ directory, no user uploads to filesystem.",
      "category": "Security",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "cors",
        "security",
        "authentication",
        "validation",
        "protection",
        "safe",
        "xss",
        "rate limit"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_deployment",
      "question": "How is the application deployed?",
      "answer": "**Backend**: Deployed to Render.com as a Python Web Service. Uses `requirements.txt` for dependencies. Start command: `uvicorn main:app --host 0.0.0.0 --port $PORT`. **Frontend**: Deployed to Vercel (recommended) or Render Static Site. Build command: `npm run build`. Output: `.next/` folder. **Environment**: Set `GEMINI_API_KEY` in Render dashboard, `NEXT_PUBLIC_API_URL` in Vercel. **Local Dev**: `npm run dev` for frontend (port 3000), `python main.py` for backend (port 8000). Both auto-reload on file changes.",
      "category": "Deployment",
      "code_refs": [
        "backend/requirements.txt",
        "frontend/package.json"
      ],
      "keywords": [
        "deployment",
        "deploy",
        "render",
        "vercel",
        "production",
        "hosting",
        "cloud",
        "server"
      ],
      "created_at": "2025-12-14T15:00:00.000000"
    },
    {
      "id": "wiki_troubleshoot_websocket",
      "question": "Interview not loading or WebSocket not connecting?",
      "answer": "**WebSocket Connection Issues**: 1) Check browser console for 'WebSocket connection failed' errors. 2) Verify backend is running on port 8000 (`python main.py`). 3) Check CORS: frontend URL must be in allowed origins. 4) Try hard refresh (Ctrl+Shift+R). 5) Check session_id in URL is valid. 6) Verify `interview_sessions.json` has the session. **Common Causes**: Backend not running, firewall blocking WebSocket, expired session (>6 hours old), typo in session_id. **Fix**: Restart backend, clear browser cache, create new session.",
      "category": "Troubleshooting",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "not loading",
        "websocket error",
        "connection failed",
        "not connecting",
        "stuck",
        "blank page",
        "troubleshoot"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_troubleshoot_feedback",
      "question": "Feedback generation failing or taking too long?",
      "answer": "**Feedback Generation Issues**: 1) Check `GEMINI_API_KEY` is valid and has quota. 2) Gemini API may be rate-limited - wait 1 minute and retry. 3) Long transcripts may timeout - try 'short' type first. 4) Check backend logs for LLM errors. **Solutions**: Verify API key in environment, check Google AI Studio for quota, reduce transcript length (fewer questions), restart backend. **Fallback**: If LLM fails, edit feedback manually in the text area before approving.",
      "category": "Troubleshooting",
      "code_refs": [
        "backend/agents/feedback_agent.py",
        "backend/llm/gemini_client.py"
      ],
      "keywords": [
        "feedback error",
        "generation failed",
        "timeout",
        "api error",
        "not generating",
        "slow",
        "stuck generating"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_troubleshoot_session",
      "question": "Session shows as Unknown or candidate info missing?",
      "answer": "**Missing Candidate Info**: 1) Candidate didn't complete init_session WebSocket handshake. 2) Browser closed before candidate form submitted. 3) Session created via direct URL without form. **Solutions**: Use Quick Start form properly, ensure stable internet during connection. **Cleanup**: Click 'Abandon' on orphaned session, 'Clean Up Stale' removes old Unknown sessions. **Prevention**: Wait for 'Connected' status before proceeding in admin view.",
      "category": "Troubleshooting",
      "code_refs": [
        "backend/models/interview_sessions.json"
      ],
      "keywords": [
        "unknown",
        "missing info",
        "empty candidate",
        "no name",
        "broken session",
        "incomplete"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_faq_time_limit",
      "question": "What happens when interview time runs out?",
      "answer": "When timer reaches 0: 1) Both views show 'Time's Up!' indicator. 2) Candidate can still submit current answer. 3) Interview does NOT auto-end - admin must click 'End Interview'. 4) This allows grace period for final response. 5) After ending, results are saved normally. **Note**: Timer is client-side, synced from session start timestamp. Admin can end interview at any time regardless of timer.",
      "category": "FAQ",
      "code_refs": [
        "frontend/src/components/AdminDashboard.tsx"
      ],
      "keywords": [
        "time limit",
        "timer",
        "expired",
        "run out",
        "finish",
        "overtime",
        "what happens"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_faq_languages",
      "question": "What programming languages are supported?",
      "answer": "Currently supported: **Python** and **Java**. Language selection: 1) Chosen in Quick Start form or position config. 2) Affects which question bank is loaded (`questions/python.json` or `questions/java.json`). 3) Sets code editor syntax highlighting. 4) Filters question bank by `language` field. **Adding Languages**: Create `questions/{language}.json`, add to language dropdown. Backend auto-detects language files. Rubrics and expected_keywords should be language-specific.",
      "category": "FAQ",
      "code_refs": [
        "backend/questions/"
      ],
      "keywords": [
        "languages",
        "python",
        "java",
        "supported",
        "programming",
        "which languages",
        "options"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_faq_question_count",
      "question": "How many questions are asked in an interview?",
      "answer": "Question count is configured per interview: **Quick Start**: Define in category settings (e.g., coding:2, conceptual:3). **Position Mode**: Set in position's `interview_config.categories`. **Follow-ups**: Up to 2 per question (configurable via `MAX_FOLLOWUPS_PER_QUESTION`). **Total**: Primary questions + follow-ups. Example: 5 primary × 2 follow-ups max = up to 15 responses. Interview can end early if admin chooses. Question bank has ~50+ questions total across categories.",
      "category": "FAQ",
      "code_refs": [
        "backend/config.py"
      ],
      "keywords": [
        "how many questions",
        "count",
        "number",
        "total questions",
        "per interview"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_faq_scoring_range",
      "question": "What do the scores mean? How is the final score calculated?",
      "answer": "**Score Range**: 0-100 for every question. **Per-Question**: Weighted average of rubric criteria (factual correctness, completeness, technical accuracy, etc.). **Overall Score**: Average of all question scores. **Interpretation**: 0-40 = Poor, 40-60 = Below Average, 60-75 = Average, 75-90 = Good, 90-100 = Excellent. **True/False**: 0 or 100 based on correct answer (weighted by `deterministic_answer.weight`, typically 65%). **Feedback**: LLM uses scores to determine hire recommendation.",
      "category": "FAQ",
      "code_refs": [
        "backend/evaluation/evaluator.py"
      ],
      "keywords": [
        "scores",
        "meaning",
        "range",
        "calculate",
        "overall",
        "final score",
        "interpretation"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_faq_edit_feedback",
      "question": "Can I edit AI-generated feedback before publishing?",
      "answer": "Yes! Feedback is fully editable before approval. **Workflow**: 1) Generate feedback via 'Generate Report'. 2) Content appears in editable text area. 3) Modify any text - fix errors, add notes, adjust tone. 4) Click 'Approve & Publish' to save edited version. 5) Published content is what you edited, not original AI text. **Tips**: Check technical accuracy, verify candidate name spelling, add specific observations. Markdown formatting supported.",
      "category": "FAQ",
      "code_refs": [
        "frontend/src/components/ResultsHistory.tsx"
      ],
      "keywords": [
        "edit",
        "modify",
        "change",
        "feedback",
        "customize",
        "before publish",
        "editable"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_layman_start_interview",
      "question": "How do I start an interview?",
      "answer": "**Quick Start (Recommended)**: 1) Click 'Quick Start' on home page. 2) Fill form: language, duration, categories. 3) Add candidate info. 4) Click 'Start Interview'. 5) Share candidate link from next screen. **Position Mode**: 1) Select Organization → Account → Position. 2) Choose candidate from matched list. 3) Click 'Start Interview'. Both methods create session and open admin dashboard. Candidate needs separate link to join.",
      "category": "Getting Started",
      "code_refs": [
        "frontend/src/app/active/page.tsx"
      ],
      "keywords": [
        "start",
        "begin",
        "how to",
        "create",
        "new interview",
        "initiate",
        "launch"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_layman_share_results",
      "question": "How do I share results with hiring manager?",
      "answer": "**Sharing Published Results**: 1) Go to Results page. 2) Find the result (must be 'Published' status). 3) Click 'Share' button. 4) Modal shows: URL and QR code. 5) Copy link or screenshot QR. 6) Send to hiring manager via email/Slack. **Public Page**: Recipients see: candidate name, date, feedback summary. No login required. Mobile-friendly. Permanent link (doesn't expire).",
      "category": "Getting Started",
      "code_refs": [
        "frontend/src/components/ShareModal.tsx"
      ],
      "keywords": [
        "share",
        "send",
        "hiring manager",
        "link",
        "results",
        "report",
        "distribute"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_layman_see_answers",
      "question": "Can I see what the candidate typed during interview?",
      "answer": "**During Interview**: Yes! Admin dashboard shows real-time view of candidate's answer as they type, including code. **After Interview**: Yes! Click 'Review' on result → Transcript shows all Q&A pairs with individual scores. Per-response breakdown available. **Limitations**: Code is captured at submit time, not intermediate edits. Transcript stored in result file permanently.",
      "category": "Getting Started",
      "code_refs": [
        "frontend/src/components/AdminDashboard.tsx"
      ],
      "keywords": [
        "see answers",
        "view",
        "candidate typed",
        "responses",
        "transcript",
        "what did they say"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_layman_custom_questions",
      "question": "Can I add my own questions?",
      "answer": "**Yes, via Question Bank**: 1) Edit `backend/models/question_bank.json`. 2) Add question object with: id, type, text, expected_keywords, evaluation_rubric. 3) Set category and difficulty. 4) Restart backend. **Expert Mode**: During interview, admin can type custom follow-up questions in real-time (override AI). **Language-Specific**: For Quick Start, edit `questions/python.json` or `java.json`. Questions auto-load on next interview start.",
      "category": "Getting Started",
      "code_refs": [
        "backend/models/question_bank.json"
      ],
      "keywords": [
        "custom",
        "own questions",
        "add",
        "create",
        "my questions",
        "new question"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_layman_candidate_join",
      "question": "How does the candidate join the interview?",
      "answer": "**Candidate Link**: 1) After admin starts interview, copy candidate URL from dashboard. 2) Format: `{domain}/interview?view=candidate&session_id=X`. 3) Send to candidate via email/message. 4) Candidate clicks link, browser opens interview page. 5) Connection auto-established via WebSocket. **No Login**: Candidates don't need accounts - direct link access. **One Device**: One candidate connection per session.",
      "category": "Getting Started",
      "code_refs": [
        "frontend/src/app/interview/page.tsx"
      ],
      "keywords": [
        "candidate join",
        "link",
        "how to connect",
        "join interview",
        "send link",
        "invite"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_layman_end_interview",
      "question": "How do I end an interview?",
      "answer": "**Admin Ends Interview**: 1) Click 'End Interview' button on admin dashboard. 2) Confirm in popup. 3) Both views show 'Interview Complete' message. 4) Results auto-saved to candidate_results folder. 5) Interview appears in Results page as 'Pending Review'. **Cannot Un-End**: Once ended, cannot resume - create new session if needed. **Candidate Cannot End**: Only admin can terminate session. Timer expiry doesn't auto-end.",
      "category": "Getting Started",
      "code_refs": [
        "frontend/src/components/AdminDashboard.tsx"
      ],
      "keywords": [
        "end",
        "finish",
        "complete",
        "stop",
        "terminate",
        "close interview",
        "done"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_layman_retry_interview",
      "question": "Can I interview the same candidate again?",
      "answer": "**Yes!** Multiple interviews per candidate are supported. **How**: 1) Start new Quick Start interview. 2) Enter same candidate name/email. 3) Results append to existing candidate file (don't overwrite). **Result File**: `candidate_results/{name}+{date}_result.json` has `interviews: []` array. Each interview adds new record. **History**: All interviews visible in results list. Each can have separate feedback. Useful for: re-interviews, different languages, follow-up rounds.",
      "category": "Getting Started",
      "code_refs": [
        "backend/candidate_results/"
      ],
      "keywords": [
        "retry",
        "again",
        "repeat",
        "another interview",
        "re-interview",
        "multiple",
        "second chance"
      ],
      "created_at": "2025-12-14T15:01:00.000000"
    },
    {
      "id": "wiki_c2ee5f9d",
      "question": "how is ws working here",
      "answer": "WebSocket (ws) communication facilitates real-time interaction during interviews. Specifically, it enables streaming of candidate responses and immediate feedback from the AI. The backend, defined in `main.py`, establishes WebSocket endpoints. When a new interview starts, a ws connection is initiated between the candidate's and admin's clients and the server. Candidate responses (text or audio transcripts) are sent *via* this WebSocket to the backend. The backend then routes these responses to the `evaluation/` module for scoring and to the `strategies/` module to determine appropriate follow-up questions. The `llm/` module (Gemini integration) is also leveraged during evaluation.  The determined follow-up question is then pushed *back* to both the candidate and admin clients *through* the same WebSocket connection, ensuring a dynamic, conversational flow. This bidirectional, persistent connection avoids the overhead of repeated HTTP requests, making the interview experience more responsive. The frontend `Interview` component handles establishing and maintaining this WebSocket connection.",
      "category": "General",
      "code_refs": [
        "backend/main.py",
        "backend/evaluation/",
        "backend/strategies/",
        "frontend/Interview/"
      ],
      "keywords": [
        "websocket",
        "real-time",
        "interview",
        "streaming",
        "fastapi",
        "communication",
        "bidirectional",
        "ai feedback"
      ],
      "created_at": "2025-12-14T15:15:05.319142",
      "auto_generated": true
    },
    {
      "id": "wiki_811b34eb",
      "question": "How does candidate matching work in this platform?",
      "answer": "Candidate matching in the AI Interview Platform determines the suitability of candidates for open positions based on a calculated match score. The core logic resides in `backend/main.py` within the `calculate_candidate_match_score` function. This function assesses match quality across several dimensions. First, it filters candidates based on a required primary language (currently Python or Java). Then, it evaluates skill overlap between the position's requirements and the candidate's skills. Importantly, the system supports *partial skill matching*; for example, a candidate skilled in Django is considered a partial match for positions requiring Python. Experience level alignment is also factored into the score. The function combines these factors – skill match, language fit, and experience – to generate an overall percentage match score ranging from 0 to 100. Higher scores indicate a stronger alignment between the candidate and the position. This score is then used to rank and present candidates.",
      "category": "General",
      "code_refs": [
        "backend/main.py"
      ],
      "keywords": [
        "candidate matching",
        "skill matching",
        "experience alignment",
        "scoring",
        "filtering",
        "python",
        "java",
        "relevance"
      ],
      "created_at": "2025-12-14T15:23:56.910379",
      "auto_generated": true
    },
    {
      "id": "wiki_a95b4cd2",
      "question": "list of active interview sessions?",
      "answer": "The AI Interview Platform tracks active interview sessions within the `InterviewController` class (backend/core/interview_controller.py). When a new interview is initiated (likely via an API call handled elsewhere, but managed by this controller), a WebSocket connection is established. This connection remains active for the duration of the interview. The `InterviewController` maintains a record of all currently open WebSocket connections. Each connection represents an ongoing interview session. The controller uses these active connections to route questions to the candidate and receive their answers. It also manages the interview state – progressing through questions, handling follow-ups (in expert mode), and coordinating with the `QuestionManager` and `Evaluator` components. Essentially, the presence of an active WebSocket connection managed by the `InterviewController` *is* an active interview session. The controller doesn't explicitly maintain a separate \"list\" of sessions; the WebSocket connections themselves serve as that list. When a connection closes (interview ends), the session is considered finished and removed from the active set.",
      "category": "General",
      "code_refs": [
        "backend/core/interview_controller.py"
      ],
      "keywords": [
        "interview",
        "session",
        "websocket",
        "active",
        "lifecycle",
        "controller",
        "connection",
        "state"
      ],
      "created_at": "2025-12-14T15:26:21.510803",
      "auto_generated": true,
      "_match_score": 0.75625
    }
  ],
  "semantic_index": {
    "synonym_mappings": {
      "architecture": [
        "design",
        "structure",
        "system",
        "setup",
        "how built",
        "tech stack",
        "framework",
        "stack",
        "app design",
        "overview",
        "how made",
        "built with",
        "technology",
        "infra",
        "infrastructure"
      ],
      "interview": [
        "test",
        "assessment",
        "evaluation",
        "session",
        "meeting",
        "conversation",
        "exam",
        "screening",
        "call",
        "round",
        "tech interview",
        "coding test",
        "viva"
      ],
      "candidate": [
        "applicant",
        "user",
        "person",
        "interviewee",
        "jobseeker",
        "dev",
        "developer",
        "engineer",
        "guy",
        "guy applying",
        "applying person",
        "examinee"
      ],
      "admin": [
        "interviewer",
        "manager",
        "host",
        "panel",
        "expert",
        "hr",
        "recruiter",
        "hiring manager",
        "me",
        "i",
        "we",
        "conductor",
        "panelist"
      ],
      "question": [
        "query",
        "ask",
        "prompt",
        "problem",
        "challenge",
        "ques",
        "q",
        "asked",
        "asking",
        "queries"
      ],
      "evaluation": [
        "scoring",
        "grading",
        "assessment",
        "rating",
        "marks",
        "points",
        "grade",
        "score",
        "eval",
        "how scored",
        "how graded",
        "judging",
        "marking"
      ],
      "feedback": [
        "report",
        "result",
        "summary",
        "review",
        "outcome",
        "assessment report",
        "verdict",
        "output",
        "final report",
        "candidate report",
        "performance"
      ],
      "websocket": [
        "realtime",
        "live",
        "sync",
        "connection",
        "socket",
        "ws",
        "real time",
        "real-time",
        "live sync",
        "instant",
        "push",
        "stream"
      ],
      "session": [
        "interview",
        "meeting",
        "test",
        "assessment",
        "active",
        "ongoing",
        "current",
        "live session",
        "running"
      ],
      "code": [
        "programming",
        "coding",
        "script",
        "program",
        "write code",
        "coding question",
        "write",
        "implement",
        "solution"
      ],
      "sharing": [
        "share",
        "link",
        "public",
        "send",
        "distribute",
        "qr",
        "qr code",
        "copy link",
        "shareable",
        "public link",
        "external link"
      ],
      "llm": [
        "ai",
        "gemini",
        "gpt",
        "model",
        "artificial intelligence",
        "machine learning",
        "ml",
        "chatgpt",
        "genai",
        "gen ai",
        "generative",
        "bot"
      ],
      "storage": [
        "database",
        "save",
        "store",
        "persist",
        "data",
        "json",
        "file",
        "db",
        "saved",
        "stored",
        "where saved",
        "files",
        "persistence"
      ],
      "quick_start": [
        "adhoc",
        "instant",
        "immediate",
        "fast",
        "simple mode",
        "quick",
        "fast start",
        "instant start",
        "easy mode",
        "quick mode",
        "quickstart",
        "qs"
      ],
      "expert_mode": [
        "admin control",
        "approval",
        "manual",
        "review mode",
        "approve first",
        "manual mode",
        "controlled",
        "human in loop",
        "hitl"
      ],
      "follow_up": [
        "next question",
        "probe",
        "dig deeper",
        "clarify",
        "followup",
        "follow up",
        "probing",
        "drill down",
        "more questions"
      ],
      "api": [
        "endpoint",
        "rest",
        "route",
        "url",
        "http",
        "backend api",
        "service",
        "api call",
        "request",
        "post",
        "get"
      ],
      "frontend": [
        "ui",
        "interface",
        "screen",
        "page",
        "view",
        "component",
        "react",
        "next",
        "nextjs",
        "client",
        "browser",
        "web"
      ],
      "backend": [
        "server",
        "api",
        "fastapi",
        "python",
        "uvicorn",
        "service",
        "api server",
        "backend server"
      ],
      "start": [
        "begin",
        "create",
        "initiate",
        "launch",
        "kick off",
        "kickoff",
        "open",
        "new",
        "starting",
        "how to start"
      ],
      "end": [
        "finish",
        "complete",
        "stop",
        "terminate",
        "close",
        "done",
        "wrap up",
        "ending",
        "over"
      ],
      "score": [
        "marks",
        "points",
        "grade",
        "rating",
        "result",
        "percentage",
        "how much",
        "how many marks",
        "graded"
      ],
      "results": [
        "outcomes",
        "output",
        "history",
        "past",
        "completed",
        "finished",
        "done interviews",
        "previous"
      ],
      "timer": [
        "time",
        "duration",
        "countdown",
        "clock",
        "minutes",
        "how long",
        "time limit",
        "timeout"
      ],
      "approve": [
        "publish",
        "confirm",
        "accept",
        "ok",
        "finalize",
        "release",
        "make public",
        "go live"
      ],
      "reject": [
        "deny",
        "decline",
        "cancel",
        "refuse",
        "not approve",
        "discard",
        "throw away"
      ],
      "status": [
        "state",
        "condition",
        "stage",
        "where",
        "at what point",
        "current state",
        "progress"
      ],
      "error": [
        "issue",
        "problem",
        "bug",
        "fail",
        "failing",
        "broken",
        "not working",
        "crash",
        "exception"
      ],
      "config": [
        "settings",
        "configuration",
        "setup",
        "env",
        "environment",
        "options",
        "parameters"
      ],
      "share": [
        "send",
        "give",
        "forward",
        "distribute",
        "copy",
        "link"
      ],
      "join": [
        "connect",
        "enter",
        "access",
        "open",
        "get in",
        "login",
        "sign in"
      ],
      "view": [
        "see",
        "look",
        "check",
        "show",
        "display",
        "watch",
        "observe"
      ],
      "edit": [
        "modify",
        "change",
        "update",
        "fix",
        "alter",
        "tweak",
        "adjust"
      ],
      "delete": [
        "remove",
        "erase",
        "clear",
        "trash",
        "discard",
        "drop"
      ],
      "create": [
        "add",
        "new",
        "make",
        "build",
        "generate",
        "insert"
      ],
      "list": [
        "show",
        "display",
        "get",
        "fetch",
        "all",
        "view all"
      ],
      "search": [
        "find",
        "lookup",
        "query",
        "look for",
        "filter",
        "locate"
      ],
      "help": [
        "how to",
        "what is",
        "explain",
        "guide",
        "tutorial",
        "docs",
        "documentation"
      ]
    },
    "shortform_mappings": {
      "ws": "websocket",
      "qs": "quick_start",
      "ui": "frontend",
      "api": "api",
      "db": "storage",
      "ai": "llm",
      "ml": "llm",
      "hr": "admin",
      "q": "question",
      "qna": "interview",
      "faq": "help",
      "cfg": "config",
      "env": "config",
      "err": "error",
      "eval": "evaluation",
      "fb": "feedback",
      "sess": "session",
      "cand": "candidate",
      "int": "interview",
      "res": "results",
      "qr": "sharing"
    },
    "topic_aliases": {
      "how it works": [
        "architecture",
        "interview",
        "websocket",
        "evaluation",
        "session"
      ],
      "getting started": [
        "quick_start",
        "session",
        "interview",
        "start",
        "begin"
      ],
      "scoring": [
        "evaluation",
        "feedback",
        "results",
        "score",
        "marks"
      ],
      "realtime": [
        "websocket",
        "sync",
        "live",
        "instant"
      ],
      "ai features": [
        "llm",
        "gemini",
        "follow_up",
        "feedback"
      ],
      "data": [
        "storage",
        "results",
        "session",
        "question"
      ],
      "troubleshoot": [
        "error",
        "problem",
        "fix",
        "not working"
      ],
      "basics": [
        "start",
        "end",
        "join",
        "view",
        "create"
      ],
      "admin stuff": [
        "admin",
        "approve",
        "reject",
        "expert_mode"
      ]
    },
    "layman_patterns": [
      {
        "pattern": "how does * work",
        "maps_to": [
          "architecture",
          "interview",
          "evaluation",
          "websocket"
        ]
      },
      {
        "pattern": "what is *",
        "maps_to": [
          "architecture",
          "quick_start",
          "expert_mode",
          "evaluation"
        ]
      },
      {
        "pattern": "where is * stored",
        "maps_to": [
          "storage",
          "results"
        ]
      },
      {
        "pattern": "how to *",
        "maps_to": [
          "start",
          "end",
          "share",
          "create",
          "join"
        ]
      },
      {
        "pattern": "can I *",
        "maps_to": [
          "edit",
          "delete",
          "share",
          "create",
          "view"
        ]
      },
      {
        "pattern": "why *",
        "maps_to": [
          "architecture",
          "evaluation",
          "feedback"
        ]
      },
      {
        "pattern": "what happens when *",
        "maps_to": [
          "interview",
          "timer",
          "error",
          "end"
        ]
      },
      {
        "pattern": "how do I *",
        "maps_to": [
          "start",
          "end",
          "share",
          "approve",
          "reject"
        ]
      },
      {
        "pattern": "tell me about *",
        "maps_to": [
          "architecture",
          "evaluation",
          "frontend",
          "backend"
        ]
      },
      {
        "pattern": "explain *",
        "maps_to": [
          "architecture",
          "evaluation",
          "scoring",
          "websocket"
        ]
      },
      {
        "pattern": "show me *",
        "maps_to": [
          "results",
          "list",
          "view",
          "frontend"
        ]
      },
      {
        "pattern": "what are the *",
        "maps_to": [
          "status",
          "score",
          "question",
          "api"
        ]
      },
      {
        "pattern": "is there *",
        "maps_to": [
          "api",
          "frontend",
          "config",
          "help"
        ]
      },
      {
        "pattern": "* not working",
        "maps_to": [
          "error",
          "troubleshoot",
          "websocket"
        ]
      },
      {
        "pattern": "* failed",
        "maps_to": [
          "error",
          "troubleshoot",
          "feedback"
        ]
      },
      {
        "pattern": "* broken",
        "maps_to": [
          "error",
          "troubleshoot"
        ]
      }
    ],
    "indexed_topics": [
      {
        "topic": "api_endpoints",
        "entry_ids": [
          "wiki_api_quickstart",
          "wiki_api_active_sessions",
          "wiki_api_cleanup",
          "wiki_api_abandon",
          "wiki_api_websocket",
          "wiki_api_results_list",
          "wiki_api_feedback_generate",
          "wiki_api_feedback_approve",
          "wiki_api_feedback_reject",
          "wiki_api_result_status",
          "wiki_api_organizations",
          "wiki_api_accounts",
          "wiki_api_positions",
          "wiki_api_share_create",
          "wiki_api_share_view",
          "wiki_api_wiki_ask",
          "wiki_api_wiki_reindex"
        ]
      },
      {
        "topic": "core_modules",
        "entry_ids": [
          "wiki_core_interview_controller",
          "wiki_core_evaluator",
          "wiki_core_gemini_client",
          "wiki_core_feedback_agent",
          "wiki_core_connection_manager",
          "wiki_core_question_manager",
          "wiki_strategy_factory",
          "wiki_strategy_depth",
          "wiki_strategy_breadth",
          "wiki_scoring_algorithms",
          "wiki_search_algorithm"
        ]
      },
      {
        "topic": "data_storage",
        "entry_ids": [
          "wiki_data_models_overview",
          "wiki_data_session_structure",
          "wiki_data_question_types",
          "wiki_data_result_format",
          "wiki_data_question_rubric",
          "wiki_session_statuses",
          "wiki_feedback_statuses"
        ]
      },
      {
        "topic": "frontend",
        "entry_ids": [
          "wiki_frontend_dashboard",
          "wiki_frontend_interview_page",
          "wiki_frontend_results_page",
          "wiki_frontend_candidate_view",
          "wiki_frontend_admin_dashboard",
          "wiki_frontend_code_editor",
          "wiki_frontend_share_modal",
          "wiki_frontend_quick_start_form",
          "wiki_frontend_feedback_modal"
        ]
      },
      {
        "topic": "getting_started",
        "entry_ids": [
          "wiki_layman_start_interview",
          "wiki_layman_share_results",
          "wiki_layman_see_answers",
          "wiki_layman_custom_questions",
          "wiki_layman_candidate_join",
          "wiki_layman_end_interview",
          "wiki_layman_retry_interview"
        ]
      },
      {
        "topic": "troubleshooting",
        "entry_ids": [
          "wiki_troubleshoot_websocket",
          "wiki_troubleshoot_feedback",
          "wiki_troubleshoot_session",
          "wiki_error_handling"
        ]
      },
      {
        "topic": "faq",
        "entry_ids": [
          "wiki_faq_time_limit",
          "wiki_faq_languages",
          "wiki_faq_question_count",
          "wiki_faq_scoring_range",
          "wiki_faq_edit_feedback"
        ]
      },
      {
        "topic": "config",
        "entry_ids": [
          "wiki_config_env",
          "wiki_security_cors",
          "wiki_deployment",
          "wiki_ports_001"
        ]
      }
    ],
    "scoring_weights": {
      "exact_keyword_match": 1.0,
      "synonym_match": 0.85,
      "shortform_match": 0.9,
      "pattern_match": 0.7,
      "topic_match": 0.6,
      "partial_match": 0.4
    },
    "version": "3.0",
    "last_indexed": "2025-12-14T15:10:00.000000"
  },
  "metadata": {
    "total_queries": 10,
    "llm_calls": 4,
    "cache_hits": 6
  }
}